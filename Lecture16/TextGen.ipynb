{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py:2717: DtypeWarning: Columns (15,30,31,32,36,37,38,42,43,44,45,46,47,50,51,52,56,57,58,59,60,61,62,63,64,65,66,67) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    Read a great interview with Donald Trump that ...\n",
       "1    Congratulations to Evan Lysacek for being nomi...\n",
       "2    I was on The View this morning. We talked abou...\n",
       "3    Tomorrow night's episode of The Apprentice del...\n",
       "4    Donald Trump Partners with TV1 on New Reality ...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = pd.read_csv('../../data/trump_tw.csv')\n",
    "ds.text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read a great interview with Donald Trump that appeared in The New York Times Magazine: http://tinyurl.com/qsx4o6 Congratulations to Evan Lysacek for being nominated SI sportsman of the year. He's a great guy, and he has my vote!  #EvanForSI I was on The View this morning. We talked about The Apprentice. Tonight's episode is a great one--tough, exciting and surprising. 10 pm/NBC Tomorrow night's episode of The Apprentice delivers excitement at QVC along with appearances by Isaac Mizrahi and Cathie Black. 10 pm on NBC Donald Trump Partners with TV1 on New Reality Series Entitled, Omarosa's Ultimate Merger: http://tinyurl.com/yk5m3lc I'll be appearing on Larry King Live for his final show, Thursday night at 9 p.m., CNN. Larry's been on TV for 25 years... I'll be on The Late Show with David Letterman tonight--be sure to tune in for a great show. 11:30 pm on CBS. Watch the Miss Universe competition LIVE from the Bahamas - Sunday, 8/23 @ 9pm (ET) on NBC: http://tinyurl.com/mrzad9 Watch video\n"
     ]
    }
   ],
   "source": [
    "# Take all the text together\n",
    "\n",
    "data = ' '.join([ix for ix in ds.text])\n",
    "print data[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set(['\\x83', '\\x87', '\\x8b', '\\x8f', '\\x93', '\\x97', '\\x9b', '\\x9f', ' ', '\\xa3', '$', '\\xa7', '(', '\\xab', ',', '\\xaf', '0', '\\xb3', '4', '\\xb7', '8', '\\xbb', '\\xbf', '@', '\\xc3', 'D', 'H', 'L', 'P', 'T', '\\xd7', 'X', '\\\\', '`', '\\xe3', 'd', '\\xe7', 'h', 'l', '\\xef', 'p', 't', 'x', '|', '\\x80', '\\x84', '\\x88', '\\x8c', '\\x90', '\\x94', '\\x98', '\\x9c', '\\xa0', '#', '\\xa4', \"'\", '\\xa8', '+', '\\xac', '/', '\\xb0', '3', '\\xb4', '7', '\\xb8', ';', '\\xbc', '?', 'C', '\\xc4', 'G', 'K', 'O', 'S', 'W', '[', '_', 'c', '\\xe4', 'g', '\\xe8', 'k', 'o', '\\xf0', 's', '\\xf4', 'w', '{', '\\x81', '\\x85', '\\x89', '\\n', '\\x8d', '\\x91', '\\x95', '\\x99', '\\x9d', '\\xa1', '\"', '\\xa5', '&', '\\xa9', '*', '\\xad', '.', '\\xb1', '2', '\\xb5', '6', '\\xb9', ':', '\\xbd', 'B', '\\xc5', 'F', 'J', 'N', 'R', 'V', 'Z', '\\xe1', 'b', '\\xe5', 'f', '\\xe9', 'j', 'n', 'r', 'v', 'z', '~', '\\x82', '\\x86', '\\x8a', '\\r', '\\x8e', '\\x92', '\\x96', '\\x9a', '\\x9e', '!', '\\xa2', '%', '\\xa6', ')', '\\xaa', '-', '\\xae', '1', '\\xb2', '5', '9', '\\xba', '=', '\\xbe', 'A', '\\xc2', 'E', 'I', 'M', 'Q', 'U', 'Y', ']', 'a', '\\xe2', 'e', '\\xe6', 'i', 'm', 'q', 'u', 'y', '}'])\n",
      "174\n"
     ]
    }
   ],
   "source": [
    "print set(data)\n",
    "print len(set(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create Vocab\n",
    "vocab = list(set(data))\n",
    "\n",
    "i2c, c2i = {}, {}\n",
    "\n",
    "for idx, chx in enumerate(vocab):\n",
    "    i2c[idx] = chx\n",
    "    c2i[chx] = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 17, 174)\n"
     ]
    }
   ],
   "source": [
    "def get_onehot(x):\n",
    "    # Take input a string and convert to one-hot encoding\n",
    "    vec_size = len(c2i.keys())\n",
    "    n_seq = len(x)\n",
    "    data = np.zeros((1, n_seq, vec_size))\n",
    "    \n",
    "    # For each element in the list\n",
    "    for ix in range(n_seq):\n",
    "        curr_char = x[ix]\n",
    "        oh_index = c2i[curr_char]\n",
    "        # print ix, curr_char, oh_index\n",
    "        data[:, ix, oh_index] = 1\n",
    "    return data\n",
    "\n",
    "print get_onehot('this is my string').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 112, 174)\n",
      "(1, 127, 174)\n",
      "(1, 139, 174)\n",
      "(1, 140, 174)\n",
      "(1, 116, 174)\n",
      "(1, 122, 174)\n",
      "(1, 108, 174)\n",
      "(1, 117, 174)\n",
      "(1, 115, 174)\n",
      "(1, 102, 174)\n"
     ]
    }
   ],
   "source": [
    "for ix in ds.text[:10]:\n",
    "    print get_onehot(ix).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CharNN(nn.Module):\n",
    "    def __init__(self, in_shape=None, out_shape=None, hidden_shape=None):\n",
    "        super(CharNN, self).__init__()\n",
    "        self.in_shape = in_shape\n",
    "        self.out_shape = out_shape\n",
    "        self.hidden_shape = hidden_shape\n",
    "        self.n_layers = 1\n",
    "        \n",
    "        self.rnn = nn.LSTM(\n",
    "            input_size=self.in_shape,\n",
    "            hidden_size=self.hidden_shape,\n",
    "            num_layers=self.n_layers,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.out = nn.Linear(self.hidden_shape, self.out_shape)\n",
    "    \n",
    "    def forward(self, x, h):\n",
    "        r_out, h_state = self.rnn(x, h)\n",
    "        \n",
    "        outs = []\n",
    "        for ix in range(r_out.size(1)):\n",
    "            current_out = F.softmax(self.out(r_out[:, ix, :]))\n",
    "            outs.append(current_out)\n",
    "        return torch.stack(outs, dim=1), h_state\n",
    "    \n",
    "    def predict(self, char, h=None, top_k=None):\n",
    "        if h is None:\n",
    "            h = self.init_hidden(1, gpu=False)\n",
    "        \n",
    "        x = get_onehot(char)\n",
    "        out, h = self.forward(torch.FloatTensor(x), h)\n",
    "        \n",
    "        p = out.data\n",
    "        if top_k is None:\n",
    "            top_ch = np.arange(self.out_shape)\n",
    "        else:\n",
    "            p, top_ch = p.topk(top_k)\n",
    "            top_ch = top_ch.numpy().squeeze()\n",
    "        \n",
    "        p = p.numpy().squeeze()\n",
    "        char = np.random.choice(top_ch, p=p/p.sum())\n",
    "        return i2c[char], h\n",
    "    \n",
    "    def init_hidden(self, batch_size, gpu=False):\n",
    "        if gpu:\n",
    "            return (Variable(torch.zeros(self.n_layers, batch_size, self.hidden_shape).cuda()),\n",
    "                    Variable(torch.zeros(self.n_layers, batch_size, self.hidden_shape)).cuda())\n",
    "        return (Variable(torch.zeros(self.n_layers, batch_size, self.hidden_shape)),\n",
    "                Variable(torch.zeros(self.n_layers, batch_size, self.hidden_shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CharNN(\n",
      "  (rnn): LSTM(174, 256, batch_first=True)\n",
      "  (out): Linear(in_features=256, out_features=174, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = CharNN(in_shape=174, out_shape=174, hidden_shape=256)\n",
    "model.cuda()\n",
    "print model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the weights\n",
    "model.load_state_dict(torch.load('/home/shubham/all_projects/CB/Summer_2018/data/checkpoints/text_gen/model_256h_epoch_38.ckpt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# model.predict('a', top_k=20)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set to train mode\n",
    "# model.cuda()\n",
    "model.train()\n",
    "N = 5000\n",
    "\n",
    "for epoch in range(50):\n",
    "    total_loss = 0\n",
    "    # For each sequence\n",
    "    for qx in range(N):\n",
    "        seqx = ds.text[qx]\n",
    "        h_state = model.init_hidden(1)\n",
    "        input_seq = seqx[:-1]\n",
    "        target_seq = seqx[1:]\n",
    "        \n",
    "        x = Variable(torch.FloatTensor(get_onehot(input_seq)), requires_grad=True)# .cuda()\n",
    "        y = Variable(torch.LongTensor(get_onehot(target_seq).argmax(2)))# .cuda()\n",
    "        \n",
    "        model.zero_grad()\n",
    "        pred, h_state = model.forward(x, h_state)\n",
    "        # print pred.squeeze().shape, y.shape\n",
    "        loss = criterion(pred.squeeze(), y.squeeze())\n",
    "        \n",
    "        # optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        # gradient clipping to solve exploding/vanishing grads\n",
    "        # clip = 5.0\n",
    "        # nn.utils.clip_grad_norm(net.parameters(), clip)\n",
    "        \n",
    "        optimizer.step()\n",
    "        total_loss += loss\n",
    "        if qx%(N/5) == 0:\n",
    "            print 'Loss: {} at Epoch: {} | Seq: {}'.format(loss, epoch, qx)\n",
    "        \n",
    "    print \"Overall Average Loss: {} at Epoch: {}\".format(total_loss / float(N), epoch)\n",
    "    \n",
    "    # Save model checkpoints\n",
    "    if epoch % 10 == 0:\n",
    "        torch.save(model.state_dict(), \"./data/checkpoints/text_gen/model_256h_epoch_{}.ckpt\".format(epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "or @Markettorial @Markettoristing @Marketanders @Markettorian and an amarion and an amarian and an amas and an amarinate and an amasting and an amarian and an amater and an amaring and an amas and an amarian and an amarical and an amas and an amasting and an amarinate and an amaster and an amasting and an amarian and an amappathing and an amappathing and an amarian and an amasting and an amapart and an amaring and an amasting and an amarian and an amas and an amasting and an amasping and and an amarian and an amas and an amasting and an amarinate and an amasting and an amarian and an amasting and an amarical and an amas and an amasting and an amasting and an amarian and an amarical and an amasting and an amasting and an amas and an amas and an amasting and an amarian and an amas and an amasping and and an amaring and an amasting and an amasting and an amasting and an amasting and an amarian and an amas and an amas and an amasting and an amas and an amas and an amasting and an amasting a\n"
     ]
    }
   ],
   "source": [
    "sentence = 'o'\n",
    "model.cpu()\n",
    "h_s = model.init_hidden(1, gpu=False)\n",
    "for ix in range(1000):\n",
    "    ctx = sentence[-1]\n",
    "    out, h = model.predict(ctx, h=h_s, top_k=100)\n",
    "    h_s = (h[0].data, h[1].data)\n",
    "    \n",
    "    sentence += out\n",
    "print sentence"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
